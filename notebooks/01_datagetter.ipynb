{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Getter Notebook\n",
        "\n",
        "This notebook handles all bulk data fetching for the project. It includes smart caching that checks date ranges and avoids re-fetching data unnecessarily.\n",
        "\n",
        "**Important:** This is the ONLY place where bulk data fetching should happen. Other notebooks and code should only READ already-fetched data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Add src to path\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "from src.data.fred_loader import (\n",
        "    download_series, \n",
        "    check_data_coverage, \n",
        "    get_series_date_range,\n",
        "    load_all_fred_data\n",
        ")\n",
        "from src.data.polymarket_loader import (\n",
        "    fetch_market_history,\n",
        "    check_market_exists\n",
        ")\n",
        "from src.data.fedwatch_loader import check_fedwatch_files_exist\n",
        "from src.config import FRED_SERIES\n",
        "from src.utils.logging_utils import setup_logging\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Set up logging\n",
        "setup_logging()\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Set pandas display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Set these variables at the top to control data fetching behavior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CONFIGURATION - Modify these settings as needed\n",
        "# ============================================================================\n",
        "\n",
        "# Force reload: If True, re-downloads all data regardless of what exists\n",
        "FORCE_RELOAD = False\n",
        "\n",
        "# FRED Data Configuration\n",
        "FRED_START_DATE = None  # None = all available data from FRED\n",
        "FRED_END_DATE = None    # None = today (checks if data is recent within threshold)\n",
        "FRED_RECENT_THRESHOLD_DAYS = 7  # If end_date is None, check if data is within this many days of today\n",
        "\n",
        "# Polymarket Configuration\n",
        "# List of market IDs to fetch. Add market IDs here as needed.\n",
        "POLYMARKET_MARKETS = [\n",
        "    # Example: \"market-id-here\",\n",
        "    # Add your market IDs here\n",
        "]\n",
        "\n",
        "# FedWatch Configuration\n",
        "# FedWatch files are manually downloaded Excel files.\n",
        "# List expected filenames here (optional, for validation)\n",
        "EXPECTED_FEDWATCH_FILES = None  # None = just check if any files exist\n",
        "# Example: [\"fedwatch_meeting_20240320.xlsx\", \"fedwatch_meeting_20240612.xlsx\"]\n",
        "\n",
        "# ============================================================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FRED Data\n",
        "\n",
        "Download all required FRED series with smart date range checking.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading/checking 6 FRED series...\n",
            "Force reload: False\n",
            "End date: today (checking if data is within 7 days)\n",
            "\n",
            "✓ DGS2: Data covers range: 1976-06-01 to 2025-11-14\n",
            "✓ DGS10: Data covers range: 1962-01-02 to 2025-11-14\n",
            "↓ UNRATE: Data is 109 days old (max date: 2025-08-01), threshold: 7 days - Downloading...\n",
            "2025-11-18 14:02:28 - src.data.fred_loader - INFO - Downloading FRED series: UNRATE\n",
            "2025-11-18 14:02:30 - src.data.fred_loader - INFO - Saved UNRATE to /home/bitzaven/CodingProjects/ExamplesFixedIncomeModelling/data/raw/fred/UNRATE.csv\n",
            "↓ CPIAUCSL: Data is 78 days old (max date: 2025-09-01), threshold: 7 days - Downloading...\n",
            "2025-11-18 14:02:30 - src.data.fred_loader - INFO - Downloading FRED series: CPIAUCSL\n",
            "2025-11-18 14:02:31 - src.data.fred_loader - INFO - Saved CPIAUCSL to /home/bitzaven/CodingProjects/ExamplesFixedIncomeModelling/data/raw/fred/CPIAUCSL.csv\n",
            "↓ FEDFUNDS: Data is 48 days old (max date: 2025-10-01), threshold: 7 days - Downloading...\n",
            "2025-11-18 14:02:31 - src.data.fred_loader - INFO - Downloading FRED series: FEDFUNDS\n",
            "2025-11-18 14:02:33 - src.data.fred_loader - INFO - Saved FEDFUNDS to /home/bitzaven/CodingProjects/ExamplesFixedIncomeModelling/data/raw/fred/FEDFUNDS.csv\n",
            "↓ GDPC1: Data is 231 days old (max date: 2025-04-01), threshold: 7 days - Downloading...\n",
            "2025-11-18 14:02:33 - src.data.fred_loader - INFO - Downloading FRED series: GDPC1\n",
            "2025-11-18 14:02:34 - src.data.fred_loader - INFO - Saved GDPC1 to /home/bitzaven/CodingProjects/ExamplesFixedIncomeModelling/data/raw/fred/GDPC1.csv\n",
            "\n",
            "FRED Summary:\n",
            "  Downloaded: 4\n",
            "  Skipped: 2\n",
            "  Errors: 0\n"
          ]
        }
      ],
      "source": [
        "# Get FRED API key\n",
        "api_key = os.getenv(\"FRED_API_KEY\")\n",
        "if not api_key:\n",
        "    print(\"WARNING: FRED_API_KEY not found in environment.\")\n",
        "    print(\"Please set it in a .env file or as an environment variable.\")\n",
        "    print(\"Skipping FRED data download.\")\n",
        "    fred_downloaded = []\n",
        "    fred_skipped = []\n",
        "    fred_errors = []\n",
        "else:\n",
        "    print(f\"Downloading/checking {len(FRED_SERIES)} FRED series...\")\n",
        "    print(f\"Force reload: {FORCE_RELOAD}\")\n",
        "    if FRED_START_DATE:\n",
        "        print(f\"Start date: {FRED_START_DATE}\")\n",
        "    if FRED_END_DATE:\n",
        "        print(f\"End date: {FRED_END_DATE}\")\n",
        "    else:\n",
        "        print(f\"End date: today (checking if data is within {FRED_RECENT_THRESHOLD_DAYS} days)\")\n",
        "    print()\n",
        "    \n",
        "    # Convert date strings to Timestamps if provided\n",
        "    start_ts = pd.to_datetime(FRED_START_DATE) if FRED_START_DATE else None\n",
        "    end_ts = pd.to_datetime(FRED_END_DATE) if FRED_END_DATE else None\n",
        "    \n",
        "    fred_downloaded = []\n",
        "    fred_skipped = []\n",
        "    fred_errors = []\n",
        "    \n",
        "    for series_id in FRED_SERIES:\n",
        "        try:\n",
        "            if FORCE_RELOAD:\n",
        "                # Force download\n",
        "                print(f\"Force reloading {series_id}...\")\n",
        "                download_series(series_id, api_key, start_date=start_ts, end_date=end_ts)\n",
        "                fred_downloaded.append(series_id)\n",
        "            else:\n",
        "                # Check if data exists and covers required range\n",
        "                is_covered, reason = check_data_coverage(\n",
        "                    series_id,\n",
        "                    start_date=start_ts,\n",
        "                    end_date=end_ts,\n",
        "                    recent_threshold_days=FRED_RECENT_THRESHOLD_DAYS\n",
        "                )\n",
        "                \n",
        "                if is_covered:\n",
        "                    date_range = get_series_date_range(series_id)\n",
        "                    print(f\"✓ {series_id}: {reason}\")\n",
        "                    fred_skipped.append(series_id)\n",
        "                else:\n",
        "                    print(f\"↓ {series_id}: {reason} - Downloading...\")\n",
        "                    download_series(series_id, api_key, start_date=start_ts, end_date=end_ts)\n",
        "                    fred_downloaded.append(series_id)\n",
        "        except Exception as e:\n",
        "            print(f\"✗ {series_id}: Error - {e}\")\n",
        "            fred_errors.append((series_id, str(e)))\n",
        "    \n",
        "    print()\n",
        "    print(f\"FRED Summary:\")\n",
        "    print(f\"  Downloaded: {len(fred_downloaded)}\")\n",
        "    print(f\"  Skipped: {len(fred_skipped)}\")\n",
        "    print(f\"  Errors: {len(fred_errors)}\")\n",
        "    if fred_errors:\n",
        "        for series_id, error in fred_errors:\n",
        "            print(f\"    - {series_id}: {error}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FedWatch Data\n",
        "\n",
        "FedWatch data must be manually downloaded from the CME FedWatch tool website and placed in `data/raw/fedwatch/`.\n",
        "\n",
        "This section checks if the expected files exist.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FedWatch File Check:\n",
            "⚠ No FedWatch files found\n",
            "  Please manually download FedWatch Excel files and place them in data/raw/fedwatch/\n",
            "  Expected naming: fedwatch_meeting_YYYYMMDD.xlsx\n"
          ]
        }
      ],
      "source": [
        "all_exist, existing_files, missing_files = check_fedwatch_files_exist(EXPECTED_FEDWATCH_FILES)\n",
        "\n",
        "print(\"FedWatch File Check:\")\n",
        "if EXPECTED_FEDWATCH_FILES is None:\n",
        "    if all_exist:\n",
        "        print(f\"✓ Found {len(existing_files)} FedWatch file(s)\")\n",
        "        for f in existing_files:\n",
        "            print(f\"  - {f}\")\n",
        "    else:\n",
        "        print(\"⚠ No FedWatch files found\")\n",
        "        print(\"  Please manually download FedWatch Excel files and place them in data/raw/fedwatch/\")\n",
        "        print(\"  Expected naming: fedwatch_meeting_YYYYMMDD.xlsx\")\n",
        "else:\n",
        "    if all_exist:\n",
        "        print(f\"✓ All {len(existing_files)} expected FedWatch files found:\")\n",
        "        for f in existing_files:\n",
        "            print(f\"  - {f}\")\n",
        "    else:\n",
        "        print(f\"⚠ {len(missing_files)} FedWatch file(s) missing:\")\n",
        "        for f in missing_files:\n",
        "            print(f\"  - {f}\")\n",
        "        if existing_files:\n",
        "            print(f\"\\nFound {len(existing_files)} file(s):\")\n",
        "            for f in existing_files:\n",
        "                print(f\"  - {f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Polymarket Data\n",
        "\n",
        "Fetch historical data for Polymarket markets. Markets are specified in the configuration section above.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No Polymarket markets configured. Add market IDs to POLYMARKET_MARKETS in the configuration section.\n"
          ]
        }
      ],
      "source": [
        "if not POLYMARKET_MARKETS:\n",
        "    print(\"No Polymarket markets configured. Add market IDs to POLYMARKET_MARKETS in the configuration section.\")\n",
        "    polymarket_downloaded = []\n",
        "    polymarket_skipped = []\n",
        "    polymarket_errors = []\n",
        "else:\n",
        "    print(f\"Fetching/checking {len(POLYMARKET_MARKETS)} Polymarket market(s)...\")\n",
        "    print(f\"Force reload: {FORCE_RELOAD}\")\n",
        "    print()\n",
        "    \n",
        "    polymarket_downloaded = []\n",
        "    polymarket_skipped = []\n",
        "    polymarket_errors = []\n",
        "    \n",
        "    for market_id in POLYMARKET_MARKETS:\n",
        "        try:\n",
        "            if FORCE_RELOAD:\n",
        "                print(f\"Force reloading {market_id}...\")\n",
        "                fetch_market_history(market_id, force_reload=True)\n",
        "                polymarket_downloaded.append(market_id)\n",
        "            else:\n",
        "                if check_market_exists(market_id):\n",
        "                    print(f\"✓ {market_id}: Already exists, skipping\")\n",
        "                    polymarket_skipped.append(market_id)\n",
        "                else:\n",
        "                    print(f\"↓ {market_id}: Not found, fetching...\")\n",
        "                    fetch_market_history(market_id, force_reload=False)\n",
        "                    polymarket_downloaded.append(market_id)\n",
        "        except Exception as e:\n",
        "            print(f\"✗ {market_id}: Error - {e}\")\n",
        "            polymarket_errors.append((market_id, str(e)))\n",
        "    \n",
        "    print()\n",
        "    print(f\"Polymarket Summary:\")\n",
        "    print(f\"  Downloaded: {len(polymarket_downloaded)}\")\n",
        "    print(f\"  Skipped: {len(polymarket_skipped)}\")\n",
        "    print(f\"  Errors: {len(polymarket_errors)}\")\n",
        "    if polymarket_errors:\n",
        "        for market_id, error in polymarket_errors:\n",
        "            print(f\"    - {market_id}: {error}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Overall summary of data fetching operations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "DATA FETCHING SUMMARY\n",
            "============================================================\n",
            "\n",
            "FRED Data:\n",
            "  Series downloaded: 4\n",
            "    UNRATE, CPIAUCSL, FEDFUNDS, GDPC1\n",
            "  Series skipped: 2\n",
            "    DGS2, DGS10\n",
            "  Errors: 0\n",
            "\n",
            "FedWatch Data:\n",
            "  Files found: 0\n",
            "  Files missing: 0\n",
            "\n",
            "Polymarket Data: No markets configured\n",
            "\n",
            "============================================================\n",
            "Data fetching complete!\n",
            "============================================================\n",
            "\n",
            "Note: Other notebooks should only READ this data, not fetch it.\n",
            "Use this notebook (01_datagetter.ipynb) for all bulk data fetching.\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"DATA FETCHING SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "\n",
        "# FRED Summary\n",
        "if api_key:\n",
        "    print(\"FRED Data:\")\n",
        "    print(f\"  Series downloaded: {len(fred_downloaded)}\")\n",
        "    if fred_downloaded:\n",
        "        print(f\"    {', '.join(fred_downloaded)}\")\n",
        "    print(f\"  Series skipped: {len(fred_skipped)}\")\n",
        "    if fred_skipped:\n",
        "        print(f\"    {', '.join(fred_skipped)}\")\n",
        "    print(f\"  Errors: {len(fred_errors)}\")\n",
        "    print()\n",
        "else:\n",
        "    print(\"FRED Data: Skipped (no API key)\")\n",
        "    print()\n",
        "\n",
        "# FedWatch Summary\n",
        "print(\"FedWatch Data:\")\n",
        "if all_exist:\n",
        "    print(f\"  Files found: {len(existing_files)}\")\n",
        "else:\n",
        "    print(f\"  Files found: {len(existing_files)}\")\n",
        "    print(f\"  Files missing: {len(missing_files)}\")\n",
        "print()\n",
        "\n",
        "# Polymarket Summary\n",
        "if POLYMARKET_MARKETS:\n",
        "    print(\"Polymarket Data:\")\n",
        "    print(f\"  Markets downloaded: {len(polymarket_downloaded)}\")\n",
        "    if polymarket_downloaded:\n",
        "        print(f\"    {', '.join(polymarket_downloaded)}\")\n",
        "    print(f\"  Markets skipped: {len(polymarket_skipped)}\")\n",
        "    if polymarket_skipped:\n",
        "        print(f\"    {', '.join(polymarket_skipped)}\")\n",
        "    print(f\"  Errors: {len(polymarket_errors)}\")\n",
        "    print()\n",
        "else:\n",
        "    print(\"Polymarket Data: No markets configured\")\n",
        "    print()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Data fetching complete!\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "print(\"Note: Other notebooks should only READ this data, not fetch it.\")\n",
        "print(\"Use this notebook (01_datagetter.ipynb) for all bulk data fetching.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
