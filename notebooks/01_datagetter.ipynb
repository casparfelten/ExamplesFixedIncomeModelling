{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Getter Notebook\n",
        "\n",
        "This notebook handles all bulk data fetching for the project. It includes smart caching that checks date ranges and avoids re-fetching data unnecessarily.\n",
        "\n",
        "**Important:** This is the ONLY place where bulk data fetching should happen. Other notebooks and code should only READ already-fetched data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Add src to path\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "from src.data.fred_loader import (\n",
        "    download_series, \n",
        "    check_data_coverage, \n",
        "    get_series_date_range,\n",
        "    load_all_fred_data,\n",
        "    merge_fred_panel\n",
        ")\n",
        "from src.data.fedwatch_loader import (\n",
        "    download_all_fedwatch_data,\n",
        "    build_fedwatch_panel\n",
        ")\n",
        "from src.data.atlanta_mpt_loader import (\n",
        "    download_atlanta_mpt_data,\n",
        "    load_atlanta_mpt_panel\n",
        ")\n",
        "from src.data.polymarket_loader import (\n",
        "    fetch_market_history,\n",
        "    check_market_exists,\n",
        "    resample_to_daily,\n",
        "    get_polymarket_market_id\n",
        ")\n",
        "from src.config import FRED_SERIES, POLYMARKET_EVENT_MAPPING\n",
        "from src.utils.logging_utils import setup_logging\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Set up logging\n",
        "setup_logging()\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Set pandas display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Set these variables at the top to control data fetching behavior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CONFIGURATION - Modify these settings as needed\n",
        "# ============================================================================\n",
        "\n",
        "# Force reload: If True, re-downloads all data regardless of what exists\n",
        "FORCE_RELOAD = False\n",
        "\n",
        "# FRED Data Configuration\n",
        "FRED_START_DATE = None  # None = all available data from FRED\n",
        "FRED_END_DATE = None    # None = today (checks if data is recent within threshold)\n",
        "FRED_RECENT_THRESHOLD_DAYS = 7  # If end_date is None, check if data is within this many days of today\n",
        "\n",
        "# FedWatch Configuration\n",
        "FEDWATCH_START_DATE = None  # None = defaults to 2014-01-01\n",
        "FEDWATCH_END_DATE = None   # None = today\n",
        "\n",
        "# Atlanta Fed MPT Configuration\n",
        "ATLANTA_MPT_FORCE_RELOAD = False\n",
        "\n",
        "# Polymarket Configuration\n",
        "# Option 1: List market IDs directly\n",
        "POLYMARKET_MARKETS = [\n",
        "    # Example: \"market-id-here\",\n",
        "    # Add your market IDs here\n",
        "]\n",
        "\n",
        "# Option 2: Use event IDs from POLYMARKET_EVENT_MAPPING in config.py\n",
        "USE_EVENT_MAPPING = False  # If True, uses all markets from POLYMARKET_EVENT_MAPPING\n",
        "\n",
        "# ============================================================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FRED Data\n",
        "\n",
        "Download all required FRED series with smart date range checking.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading/checking 6 FRED series...\n",
            "Force reload: False\n",
            "End date: today (checking if data is within 7 days)\n",
            "\n",
            "✓ DGS2: Data covers range: 1976-06-01 to 2025-11-14\n",
            "✓ DGS10: Data covers range: 1962-01-02 to 2025-11-14\n",
            "↓ UNRATE: Data is 109 days old (max date: 2025-08-01), threshold: 7 days - Downloading...\n",
            "2025-11-18 14:02:28 - src.data.fred_loader - INFO - Downloading FRED series: UNRATE\n",
            "2025-11-18 14:02:30 - src.data.fred_loader - INFO - Saved UNRATE to /home/bitzaven/CodingProjects/ExamplesFixedIncomeModelling/data/raw/fred/UNRATE.csv\n",
            "↓ CPIAUCSL: Data is 78 days old (max date: 2025-09-01), threshold: 7 days - Downloading...\n",
            "2025-11-18 14:02:30 - src.data.fred_loader - INFO - Downloading FRED series: CPIAUCSL\n",
            "2025-11-18 14:02:31 - src.data.fred_loader - INFO - Saved CPIAUCSL to /home/bitzaven/CodingProjects/ExamplesFixedIncomeModelling/data/raw/fred/CPIAUCSL.csv\n",
            "↓ FEDFUNDS: Data is 48 days old (max date: 2025-10-01), threshold: 7 days - Downloading...\n",
            "2025-11-18 14:02:31 - src.data.fred_loader - INFO - Downloading FRED series: FEDFUNDS\n",
            "2025-11-18 14:02:33 - src.data.fred_loader - INFO - Saved FEDFUNDS to /home/bitzaven/CodingProjects/ExamplesFixedIncomeModelling/data/raw/fred/FEDFUNDS.csv\n",
            "↓ GDPC1: Data is 231 days old (max date: 2025-04-01), threshold: 7 days - Downloading...\n",
            "2025-11-18 14:02:33 - src.data.fred_loader - INFO - Downloading FRED series: GDPC1\n",
            "2025-11-18 14:02:34 - src.data.fred_loader - INFO - Saved GDPC1 to /home/bitzaven/CodingProjects/ExamplesFixedIncomeModelling/data/raw/fred/GDPC1.csv\n",
            "\n",
            "FRED Summary:\n",
            "  Downloaded: 4\n",
            "  Skipped: 2\n",
            "  Errors: 0\n"
          ]
        }
      ],
      "source": [
        "# Get FRED API key\n",
        "api_key = os.getenv(\"FRED_API_KEY\")\n",
        "if not api_key:\n",
        "    print(\"WARNING: FRED_API_KEY not found in environment.\")\n",
        "    print(\"Please set it in a .env file or as an environment variable.\")\n",
        "    print(\"Skipping FRED data download.\")\n",
        "    fred_downloaded = []\n",
        "    fred_skipped = []\n",
        "    fred_errors = []\n",
        "else:\n",
        "    print(f\"Downloading/checking {len(FRED_SERIES)} FRED series...\")\n",
        "    print(f\"Force reload: {FORCE_RELOAD}\")\n",
        "    if FRED_START_DATE:\n",
        "        print(f\"Start date: {FRED_START_DATE}\")\n",
        "    if FRED_END_DATE:\n",
        "        print(f\"End date: {FRED_END_DATE}\")\n",
        "    else:\n",
        "        print(f\"End date: today (checking if data is within {FRED_RECENT_THRESHOLD_DAYS} days)\")\n",
        "    print()\n",
        "    \n",
        "    # Convert date strings to Timestamps if provided\n",
        "    start_ts = pd.to_datetime(FRED_START_DATE) if FRED_START_DATE else None\n",
        "    end_ts = pd.to_datetime(FRED_END_DATE) if FRED_END_DATE else None\n",
        "    \n",
        "    fred_downloaded = []\n",
        "    fred_skipped = []\n",
        "    fred_errors = []\n",
        "    \n",
        "    for series_id in FRED_SERIES:\n",
        "        try:\n",
        "            if FORCE_RELOAD:\n",
        "                # Force download\n",
        "                print(f\"Force reloading {series_id}...\")\n",
        "                download_series(series_id, api_key, start_date=start_ts, end_date=end_ts)\n",
        "                fred_downloaded.append(series_id)\n",
        "            else:\n",
        "                # Check if data exists and covers required range\n",
        "                is_covered, reason = check_data_coverage(\n",
        "                    series_id,\n",
        "                    start_date=start_ts,\n",
        "                    end_date=end_ts,\n",
        "                    recent_threshold_days=FRED_RECENT_THRESHOLD_DAYS\n",
        "                )\n",
        "                \n",
        "                if is_covered:\n",
        "                    date_range = get_series_date_range(series_id)\n",
        "                    print(f\"✓ {series_id}: {reason}\")\n",
        "                    fred_skipped.append(series_id)\n",
        "                else:\n",
        "                    print(f\"↓ {series_id}: {reason} - Downloading...\")\n",
        "                    download_series(series_id, api_key, start_date=start_ts, end_date=end_ts)\n",
        "                    fred_downloaded.append(series_id)\n",
        "        except Exception as e:\n",
        "            print(f\"✗ {series_id}: Error - {e}\")\n",
        "            fred_errors.append((series_id, str(e)))\n",
        "    \n",
        "    print()\n",
        "    print(f\"FRED Summary:\")\n",
        "    print(f\"  Downloaded: {len(fred_downloaded)}\")\n",
        "    print(f\"  Skipped: {len(fred_skipped)}\")\n",
        "    print(f\"  Errors: {len(fred_errors)}\")\n",
        "    if fred_errors:\n",
        "        for series_id, error in fred_errors:\n",
        "            print(f\"    - {series_id}: {error}\")\n",
        "\n",
        "# Build processed FRED daily panel\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Building FRED Daily Panel\")\n",
        "print(\"=\"*60)\n",
        "try:\n",
        "    fred_panel = merge_fred_panel()\n",
        "    print(f\"\\n✓ FRED panel built successfully!\")\n",
        "    print(f\"  Shape: {fred_panel.shape}\")\n",
        "    print(f\"  Date range: {fred_panel['date'].min()} to {fred_panel['date'].max()}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(fred_panel.head())\n",
        "    print(f\"\\nColumns: {list(fred_panel.columns)}\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Error building FRED panel: {e}\")\n",
        "    fred_panel = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FedWatch Data (CME EOD REST API)\n",
        "\n",
        "Download FedWatch probability data from CME FedWatch EOD REST API.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FedWatch File Check:\n",
            "⚠ No FedWatch files found\n",
            "  Please manually download FedWatch Excel files and place them in data/raw/fedwatch/\n",
            "  Expected naming: fedwatch_meeting_YYYYMMDD.xlsx\n"
          ]
        }
      ],
      "source": [
        "# Check for API key\n",
        "cme_api_key = os.getenv(\"CME_FEDWATCH_API_KEY\")\n",
        "if not cme_api_key:\n",
        "    print(\"WARNING: CME_FEDWATCH_API_KEY not found in environment.\")\n",
        "    print(\"Please set it in a .env file or as an environment variable.\")\n",
        "    print(\"Skipping FedWatch data download.\")\n",
        "    fedwatch_downloaded = False\n",
        "    fedwatch_errors = []\n",
        "else:\n",
        "    print(\"Downloading FedWatch data from CME EOD REST API...\")\n",
        "    print(f\"Force reload: {FORCE_RELOAD}\")\n",
        "    if FEDWATCH_START_DATE:\n",
        "        print(f\"Start date: {FEDWATCH_START_DATE}\")\n",
        "    if FEDWATCH_END_DATE:\n",
        "        print(f\"End date: {FEDWATCH_END_DATE}\")\n",
        "    print()\n",
        "    \n",
        "    try:\n",
        "        start_ts = pd.to_datetime(FEDWATCH_START_DATE) if FEDWATCH_START_DATE else None\n",
        "        end_ts = pd.to_datetime(FEDWATCH_END_DATE) if FEDWATCH_END_DATE else None\n",
        "        \n",
        "        download_all_fedwatch_data(\n",
        "            start_date=start_ts,\n",
        "            end_date=end_ts,\n",
        "            force_reload=FORCE_RELOAD\n",
        "        )\n",
        "        fedwatch_downloaded = True\n",
        "        fedwatch_errors = []\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error downloading FedWatch data: {e}\")\n",
        "        fedwatch_downloaded = False\n",
        "        fedwatch_errors = [str(e)]\n",
        "\n",
        "# Build processed FedWatch panel\n",
        "if fedwatch_downloaded or not cme_api_key:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Building FedWatch Panel\")\n",
        "    print(\"=\"*60)\n",
        "    try:\n",
        "        fedwatch_panel = build_fedwatch_panel()\n",
        "        if not fedwatch_panel.empty:\n",
        "            print(f\"\\n✓ FedWatch panel built successfully!\")\n",
        "            print(f\"  Shape: {fedwatch_panel.shape}\")\n",
        "            print(f\"  Date range: {fedwatch_panel['as_of_date'].min()} to {fedwatch_panel['as_of_date'].max()}\")\n",
        "            print(f\"  Meetings: {fedwatch_panel['meeting_id'].nunique()} unique meetings\")\n",
        "            print(f\"\\nFirst few rows:\")\n",
        "            print(fedwatch_panel.head())\n",
        "        else:\n",
        "            print(\"⚠ FedWatch panel is empty (no data available)\")\n",
        "            fedwatch_panel = None\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error building FedWatch panel: {e}\")\n",
        "        fedwatch_panel = None\n",
        "else:\n",
        "    fedwatch_panel = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Atlanta Fed Market Probability Tracker\n",
        "\n",
        "Download and process Atlanta Fed Market Probability Tracker data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No Polymarket markets configured. Add market IDs to POLYMARKET_MARKETS in the configuration section.\n"
          ]
        }
      ],
      "source": [
        "print(\"Downloading Atlanta Fed Market Probability Tracker data...\")\n",
        "print(f\"Force reload: {ATLANTA_MPT_FORCE_RELOAD}\")\n",
        "print()\n",
        "\n",
        "try:\n",
        "    download_atlanta_mpt_data(force_reload=ATLANTA_MPT_FORCE_RELOAD)\n",
        "    atlanta_mpt_downloaded = True\n",
        "    atlanta_mpt_errors = []\n",
        "except Exception as e:\n",
        "    print(f\"✗ Error downloading Atlanta MPT data: {e}\")\n",
        "    print(\"Note: Atlanta Fed MPT data may need to be downloaded manually from their website\")\n",
        "    atlanta_mpt_downloaded = False\n",
        "    atlanta_mpt_errors = [str(e)]\n",
        "\n",
        "# Build processed Atlanta MPT panel\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Building Atlanta MPT Panel\")\n",
        "print(\"=\"*60)\n",
        "try:\n",
        "    atlanta_mpt_panel = load_atlanta_mpt_panel()\n",
        "    if not atlanta_mpt_panel.empty:\n",
        "        print(f\"\\n✓ Atlanta MPT panel built successfully!\")\n",
        "        print(f\"  Shape: {atlanta_mpt_panel.shape}\")\n",
        "        print(f\"  Date range: {atlanta_mpt_panel['as_of_date'].min()} to {atlanta_mpt_panel['as_of_date'].max()}\")\n",
        "        print(f\"  Horizons: {atlanta_mpt_panel['horizon_date'].nunique()} unique horizons\")\n",
        "        print(f\"\\nFirst few rows:\")\n",
        "        print(atlanta_mpt_panel.head())\n",
        "    else:\n",
        "        print(\"⚠ Atlanta MPT panel is empty (no data available)\")\n",
        "        atlanta_mpt_panel = None\n",
        "except Exception as e:\n",
        "    print(f\"✗ Error building Atlanta MPT panel: {e}\")\n",
        "    atlanta_mpt_panel = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Polymarket Data\n",
        "\n",
        "Fetch historical data for Polymarket markets and resample to daily frequency.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Determine which markets to fetch\n",
        "markets_to_fetch = []\n",
        "if USE_EVENT_MAPPING and POLYMARKET_EVENT_MAPPING:\n",
        "    print(\"Using markets from POLYMARKET_EVENT_MAPPING...\")\n",
        "    for event_id, mapping in POLYMARKET_EVENT_MAPPING.items():\n",
        "        market_id = mapping.get(\"market_id\")\n",
        "        if market_id:\n",
        "            markets_to_fetch.append((market_id, event_id))\n",
        "    print(f\"Found {len(markets_to_fetch)} markets from event mapping\")\n",
        "else:\n",
        "    markets_to_fetch = [(m, None) for m in POLYMARKET_MARKETS]\n",
        "\n",
        "if not markets_to_fetch:\n",
        "    print(\"No Polymarket markets configured.\")\n",
        "    print(\"Add market IDs to POLYMARKET_MARKETS or configure POLYMARKET_EVENT_MAPPING in config.py\")\n",
        "    polymarket_downloaded = []\n",
        "    polymarket_skipped = []\n",
        "    polymarket_errors = []\n",
        "else:\n",
        "    print(f\"Fetching/checking {len(markets_to_fetch)} Polymarket market(s)...\")\n",
        "    print(f\"Force reload: {FORCE_RELOAD}\")\n",
        "    print()\n",
        "    \n",
        "    polymarket_downloaded = []\n",
        "    polymarket_skipped = []\n",
        "    polymarket_errors = []\n",
        "    \n",
        "    for market_id, event_id in markets_to_fetch:\n",
        "        try:\n",
        "            if FORCE_RELOAD:\n",
        "                print(f\"Force reloading {market_id}...\")\n",
        "                fetch_market_history(market_id, force_reload=True)\n",
        "                polymarket_downloaded.append(market_id)\n",
        "            else:\n",
        "                if check_market_exists(market_id):\n",
        "                    print(f\"✓ {market_id}: Already exists, skipping\")\n",
        "                    polymarket_skipped.append(market_id)\n",
        "                else:\n",
        "                    print(f\"↓ {market_id}: Not found, fetching...\")\n",
        "                    fetch_market_history(market_id, force_reload=False)\n",
        "                    polymarket_downloaded.append(market_id)\n",
        "            \n",
        "            # Resample to daily\n",
        "            print(f\"  Resampling {market_id} to daily frequency...\")\n",
        "            resample_to_daily(market_id)\n",
        "        except Exception as e:\n",
        "            print(f\"✗ {market_id}: Error - {e}\")\n",
        "            polymarket_errors.append((market_id, str(e)))\n",
        "    \n",
        "    print()\n",
        "    print(f\"Polymarket Summary:\")\n",
        "    print(f\"  Markets downloaded: {len(polymarket_downloaded)}\")\n",
        "    if polymarket_downloaded:\n",
        "        print(f\"    {', '.join(polymarket_downloaded)}\")\n",
        "    print(f\"  Markets skipped: {len(polymarket_skipped)}\")\n",
        "    if polymarket_skipped:\n",
        "        print(f\"    {', '.join(polymarket_skipped)}\")\n",
        "    print(f\"  Errors: {len(polymarket_errors)}\")\n",
        "    if polymarket_errors:\n",
        "        for market_id, error in polymarket_errors:\n",
        "            print(f\"    - {market_id}: {error}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "DATA FETCHING SUMMARY\n",
            "============================================================\n",
            "\n",
            "FRED Data:\n",
            "  Series downloaded: 4\n",
            "    UNRATE, CPIAUCSL, FEDFUNDS, GDPC1\n",
            "  Series skipped: 2\n",
            "    DGS2, DGS10\n",
            "  Errors: 0\n",
            "\n",
            "FedWatch Data:\n",
            "  Files found: 0\n",
            "  Files missing: 0\n",
            "\n",
            "Polymarket Data: No markets configured\n",
            "\n",
            "============================================================\n",
            "Data fetching complete!\n",
            "============================================================\n",
            "\n",
            "Note: Other notebooks should only READ this data, not fetch it.\n",
            "Use this notebook (01_datagetter.ipynb) for all bulk data fetching.\n"
          ]
        }
      ],
      "source": [
        "## Summary\n",
        "\n",
        "Overall summary of data fetching operations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
