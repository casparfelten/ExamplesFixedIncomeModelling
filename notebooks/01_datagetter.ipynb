{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Getter Notebook\n",
    "\n",
    "This notebook handles all bulk data fetching for the project. It includes smart caching that checks date ranges and avoids re-fetching data unnecessarily.\n",
    "\n",
    "**Important:** This is the ONLY place where bulk data fetching should happen. Other notebooks and code should only READ already-fetched data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fredapi'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m project_root = Path().resolve().parent\n\u001b[32m      8\u001b[39m sys.path.insert(\u001b[32m0\u001b[39m, \u001b[38;5;28mstr\u001b[39m(project_root))\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfred_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     download_series, \n\u001b[32m     12\u001b[39m     check_data_coverage, \n\u001b[32m     13\u001b[39m     get_series_date_range,\n\u001b[32m     14\u001b[39m     load_all_fred_data,\n\u001b[32m     15\u001b[39m     merge_fred_panel\n\u001b[32m     16\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfedwatch_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     18\u001b[39m     download_all_fedwatch_data,\n\u001b[32m     19\u001b[39m     build_fedwatch_panel\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01matlanta_mpt_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     22\u001b[39m     download_atlanta_mpt_data,\n\u001b[32m     23\u001b[39m     load_atlanta_mpt_panel\n\u001b[32m     24\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CodingProjects/ExamplesFixedIncomeModelling/src/data/fred_loader.py:7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Optional, Tuple\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfredapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Fred\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'fredapi'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Add src to path\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.data.fred_loader import (\n",
    "    download_series, \n",
    "    check_data_coverage, \n",
    "    get_series_date_range,\n",
    "    load_all_fred_data,\n",
    "    merge_fred_panel\n",
    ")\n",
    "from src.data.fedwatch_loader import (\n",
    "    download_all_fedwatch_data,\n",
    "    build_fedwatch_panel\n",
    ")\n",
    "from src.data.atlanta_mpt_loader import (\n",
    "    download_atlanta_mpt_data,\n",
    "    load_atlanta_mpt_panel\n",
    ")\n",
    "from src.data.polymarket_loader import (\n",
    "    fetch_market_history,\n",
    "    check_market_exists,\n",
    "    resample_to_daily,\n",
    "    get_polymarket_market_id\n",
    ")\n",
    "from src.data.inflation_announcements_loader import (\n",
    "    download_inflation_announcements,\n",
    "    load_inflation_announcements\n",
    ")\n",
    "from src.config import FRED_SERIES, POLYMARKET_EVENT_MAPPING\n",
    "from src.utils.logging_utils import setup_logging\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set up logging\n",
    "setup_logging()\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set these variables at the top to control data fetching behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - Modify these settings as needed\n",
    "# ============================================================================\n",
    "\n",
    "# Force reload: If True, re-downloads all data regardless of what exists\n",
    "FORCE_RELOAD = False\n",
    "\n",
    "# FRED Data Configuration\n",
    "FRED_START_DATE = None  # None = all available data from FRED\n",
    "FRED_END_DATE = None    # None = today (checks if data is recent within threshold)\n",
    "FRED_RECENT_THRESHOLD_DAYS = 7  # If end_date is None, check if data is within this many days of today\n",
    "\n",
    "# FedWatch Configuration\n",
    "FEDWATCH_START_DATE = None  # None = defaults to 2014-01-01\n",
    "FEDWATCH_END_DATE = None   # None = today\n",
    "\n",
    "# Atlanta Fed MPT Configuration\n",
    "ATLANTA_MPT_FORCE_RELOAD = False\n",
    "\n",
    "# Inflation Announcements Configuration\n",
    "INFLATION_ANNOUNCEMENTS_FORCE_RELOAD = False  # If True, re-downloads even if file exists\n",
    "INFLATION_ANNOUNCEMENTS_PREFER_SOURCE = \"fred\"  # \"fred\", \"bls\", or \"both\"\n",
    "\n",
    "# Polymarket Configuration\n",
    "# Option 1: List market IDs directly\n",
    "POLYMARKET_MARKETS = [\n",
    "    # Example: \"market-id-here\",\n",
    "    # Add your market IDs here\n",
    "]\n",
    "\n",
    "# Option 2: Use event IDs from POLYMARKET_EVENT_MAPPING in config.py\n",
    "USE_EVENT_MAPPING = False  # If True, uses all markets from POLYMARKET_EVENT_MAPPING\n",
    "\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inflation Announcements\n",
    "\n",
    "Download CPI/inflation announcement release dates from FRED API or BLS schedule.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Downloading inflation announcement release dates...\")\n",
    "print(f\"Force reload: {INFLATION_ANNOUNCEMENTS_FORCE_RELOAD}\")\n",
    "print(f\"Preferred source: {INFLATION_ANNOUNCEMENTS_PREFER_SOURCE}\")\n",
    "print()\n",
    "\n",
    "# Get FRED API key (same as used for FRED data)\n",
    "fred_api_key = os.getenv(\"FRED_API_KEY\")\n",
    "if not fred_api_key and INFLATION_ANNOUNCEMENTS_PREFER_SOURCE in [\"fred\", \"both\"]:\n",
    "    print(\"WARNING: FRED_API_KEY not found in environment.\")\n",
    "    print(\"Inflation announcements will try BLS scraping instead.\")\n",
    "    print()\n",
    "\n",
    "try:\n",
    "    download_inflation_announcements(\n",
    "        api_key=fred_api_key,  # Pass None if not found, function will handle it\n",
    "        force_reload=INFLATION_ANNOUNCEMENTS_FORCE_RELOAD,\n",
    "        prefer_source=INFLATION_ANNOUNCEMENTS_PREFER_SOURCE\n",
    "    )\n",
    "    inflation_announcements_downloaded = True\n",
    "    inflation_announcements_errors = []\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error downloading inflation announcements: {e}\")\n",
    "    inflation_announcements_downloaded = False\n",
    "    inflation_announcements_errors = [str(e)]\n",
    "\n",
    "# Load and display inflation announcements\n",
    "if inflation_announcements_downloaded:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Loading Inflation Announcements\")\n",
    "    print(\"=\"*60)\n",
    "    try:\n",
    "        inflation_announcements = load_inflation_announcements()\n",
    "        if not inflation_announcements.empty:\n",
    "            print(f\"\\n✓ Inflation announcements loaded successfully!\")\n",
    "            print(f\"  Shape: {inflation_announcements.shape}\")\n",
    "            print(f\"  Date range: {inflation_announcements['release_date'].min()} to {inflation_announcements['release_date'].max()}\")\n",
    "            print(f\"  Data periods: {inflation_announcements['data_period'].min()} to {inflation_announcements['data_period'].max()}\")\n",
    "            print(f\"  Sources: {inflation_announcements['source'].value_counts().to_dict()}\")\n",
    "            print(f\"\\nFirst few rows:\")\n",
    "            print(inflation_announcements.head(10))\n",
    "            print(f\"\\nLast few rows:\")\n",
    "            print(inflation_announcements.tail(10))\n",
    "        else:\n",
    "            print(\"⚠ Inflation announcements is empty (no data available)\")\n",
    "            inflation_announcements = None\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error loading inflation announcements: {e}\")\n",
    "        inflation_announcements = None\n",
    "else:\n",
    "    inflation_announcements = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FRED Data\n",
    "\n",
    "Download all required FRED series with smart date range checking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get FRED API key\n",
    "api_key = os.getenv(\"FRED_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"WARNING: FRED_API_KEY not found in environment.\")\n",
    "    print(\"Please set it in a .env file or as an environment variable.\")\n",
    "    print(\"Skipping FRED data download.\")\n",
    "    fred_downloaded = []\n",
    "    fred_skipped = []\n",
    "    fred_errors = []\n",
    "else:\n",
    "    print(f\"Downloading/checking {len(FRED_SERIES)} FRED series...\")\n",
    "    print(f\"Force reload: {FORCE_RELOAD}\")\n",
    "    if FRED_START_DATE:\n",
    "        print(f\"Start date: {FRED_START_DATE}\")\n",
    "    if FRED_END_DATE:\n",
    "        print(f\"End date: {FRED_END_DATE}\")\n",
    "    else:\n",
    "        print(f\"End date: today (checking if data is within {FRED_RECENT_THRESHOLD_DAYS} days)\")\n",
    "    print()\n",
    "    \n",
    "    # Convert date strings to Timestamps if provided\n",
    "    start_ts = pd.to_datetime(FRED_START_DATE) if FRED_START_DATE else None\n",
    "    end_ts = pd.to_datetime(FRED_END_DATE) if FRED_END_DATE else None\n",
    "    \n",
    "    fred_downloaded = []\n",
    "    fred_skipped = []\n",
    "    fred_errors = []\n",
    "    \n",
    "    for series_id in FRED_SERIES:\n",
    "        try:\n",
    "            if FORCE_RELOAD:\n",
    "                # Force download\n",
    "                print(f\"Force reloading {series_id}...\")\n",
    "                download_series(series_id, api_key, start_date=start_ts, end_date=end_ts)\n",
    "                fred_downloaded.append(series_id)\n",
    "            else:\n",
    "                # Check if data exists and covers required range\n",
    "                is_covered, reason = check_data_coverage(\n",
    "                    series_id,\n",
    "                    start_date=start_ts,\n",
    "                    end_date=end_ts,\n",
    "                    recent_threshold_days=FRED_RECENT_THRESHOLD_DAYS\n",
    "                )\n",
    "                \n",
    "                if is_covered:\n",
    "                    date_range = get_series_date_range(series_id)\n",
    "                    print(f\"✓ {series_id}: {reason}\")\n",
    "                    fred_skipped.append(series_id)\n",
    "                else:\n",
    "                    print(f\"↓ {series_id}: {reason} - Downloading...\")\n",
    "                    download_series(series_id, api_key, start_date=start_ts, end_date=end_ts)\n",
    "                    fred_downloaded.append(series_id)\n",
    "        except Exception as e:\n",
    "            print(f\"✗ {series_id}: Error - {e}\")\n",
    "            fred_errors.append((series_id, str(e)))\n",
    "    \n",
    "    print()\n",
    "    print(f\"FRED Summary:\")\n",
    "    print(f\"  Downloaded: {len(fred_downloaded)}\")\n",
    "    print(f\"  Skipped: {len(fred_skipped)}\")\n",
    "    print(f\"  Errors: {len(fred_errors)}\")\n",
    "    if fred_errors:\n",
    "        for series_id, error in fred_errors:\n",
    "            print(f\"    - {series_id}: {error}\")\n",
    "\n",
    "# Build processed FRED daily panel\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Building FRED Daily Panel\")\n",
    "print(\"=\"*60)\n",
    "try:\n",
    "    fred_panel = merge_fred_panel()\n",
    "    print(f\"\\n✓ FRED panel built successfully!\")\n",
    "    print(f\"  Shape: {fred_panel.shape}\")\n",
    "    print(f\"  Date range: {fred_panel['date'].min()} to {fred_panel['date'].max()}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(fred_panel.head())\n",
    "    print(f\"\\nColumns: {list(fred_panel.columns)}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error building FRED panel: {e}\")\n",
    "    fred_panel = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FedWatch Data (CME EOD REST API)\n",
    "\n",
    "Download FedWatch probability data from CME FedWatch EOD REST API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for API key\n",
    "cme_api_key = os.getenv(\"CME_FEDWATCH_API_KEY\")\n",
    "if not cme_api_key:\n",
    "    print(\"WARNING: CME_FEDWATCH_API_KEY not found in environment.\")\n",
    "    print(\"Please set it in a .env file or as an environment variable.\")\n",
    "    print(\"Skipping FedWatch data download.\")\n",
    "    fedwatch_downloaded = False\n",
    "    fedwatch_errors = []\n",
    "else:\n",
    "    print(\"Downloading FedWatch data from CME EOD REST API...\")\n",
    "    print(f\"Force reload: {FORCE_RELOAD}\")\n",
    "    if FEDWATCH_START_DATE:\n",
    "        print(f\"Start date: {FEDWATCH_START_DATE}\")\n",
    "    if FEDWATCH_END_DATE:\n",
    "        print(f\"End date: {FEDWATCH_END_DATE}\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        start_ts = pd.to_datetime(FEDWATCH_START_DATE) if FEDWATCH_START_DATE else None\n",
    "        end_ts = pd.to_datetime(FEDWATCH_END_DATE) if FEDWATCH_END_DATE else None\n",
    "        \n",
    "        download_all_fedwatch_data(\n",
    "            start_date=start_ts,\n",
    "            end_date=end_ts,\n",
    "            force_reload=FORCE_RELOAD\n",
    "        )\n",
    "        fedwatch_downloaded = True\n",
    "        fedwatch_errors = []\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error downloading FedWatch data: {e}\")\n",
    "        fedwatch_downloaded = False\n",
    "        fedwatch_errors = [str(e)]\n",
    "\n",
    "# Build processed FedWatch panel\n",
    "if fedwatch_downloaded or not cme_api_key:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Building FedWatch Panel\")\n",
    "    print(\"=\"*60)\n",
    "    try:\n",
    "        fedwatch_panel = build_fedwatch_panel()\n",
    "        if not fedwatch_panel.empty:\n",
    "            print(f\"\\n✓ FedWatch panel built successfully!\")\n",
    "            print(f\"  Shape: {fedwatch_panel.shape}\")\n",
    "            print(f\"  Date range: {fedwatch_panel['as_of_date'].min()} to {fedwatch_panel['as_of_date'].max()}\")\n",
    "            print(f\"  Meetings: {fedwatch_panel['meeting_id'].nunique()} unique meetings\")\n",
    "            print(f\"\\nFirst few rows:\")\n",
    "            print(fedwatch_panel.head())\n",
    "        else:\n",
    "            print(\"⚠ FedWatch panel is empty (no data available)\")\n",
    "            fedwatch_panel = None\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error building FedWatch panel: {e}\")\n",
    "        fedwatch_panel = None\n",
    "else:\n",
    "    fedwatch_panel = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atlanta Fed Market Probability Tracker\n",
    "\n",
    "Download and process Atlanta Fed Market Probability Tracker data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Downloading Atlanta Fed Market Probability Tracker data...\")\n",
    "print(f\"Force reload: {ATLANTA_MPT_FORCE_RELOAD}\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    download_atlanta_mpt_data(force_reload=ATLANTA_MPT_FORCE_RELOAD)\n",
    "    atlanta_mpt_downloaded = True\n",
    "    atlanta_mpt_errors = []\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error downloading Atlanta MPT data: {e}\")\n",
    "    print(\"Note: Atlanta Fed MPT data may need to be downloaded manually from their website\")\n",
    "    atlanta_mpt_downloaded = False\n",
    "    atlanta_mpt_errors = [str(e)]\n",
    "\n",
    "# Build processed Atlanta MPT panel\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Building Atlanta MPT Panel\")\n",
    "print(\"=\"*60)\n",
    "try:\n",
    "    atlanta_mpt_panel = load_atlanta_mpt_panel()\n",
    "    if not atlanta_mpt_panel.empty:\n",
    "        print(f\"\\n✓ Atlanta MPT panel built successfully!\")\n",
    "        print(f\"  Shape: {atlanta_mpt_panel.shape}\")\n",
    "        print(f\"  Date range: {atlanta_mpt_panel['as_of_date'].min()} to {atlanta_mpt_panel['as_of_date'].max()}\")\n",
    "        print(f\"  Horizons: {atlanta_mpt_panel['horizon_date'].nunique()} unique horizons\")\n",
    "        print(f\"\\nFirst few rows:\")\n",
    "        print(atlanta_mpt_panel.head())\n",
    "    else:\n",
    "        print(\"⚠ Atlanta MPT panel is empty (no data available)\")\n",
    "        atlanta_mpt_panel = None\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error building Atlanta MPT panel: {e}\")\n",
    "    atlanta_mpt_panel = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polymarket Data\n",
    "\n",
    "Fetch historical data for Polymarket markets and resample to daily frequency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which markets to fetch\n",
    "markets_to_fetch = []\n",
    "if USE_EVENT_MAPPING and POLYMARKET_EVENT_MAPPING:\n",
    "    print(\"Using markets from POLYMARKET_EVENT_MAPPING...\")\n",
    "    for event_id, mapping in POLYMARKET_EVENT_MAPPING.items():\n",
    "        market_id = mapping.get(\"market_id\")\n",
    "        if market_id:\n",
    "            markets_to_fetch.append((market_id, event_id))\n",
    "    print(f\"Found {len(markets_to_fetch)} markets from event mapping\")\n",
    "else:\n",
    "    markets_to_fetch = [(m, None) for m in POLYMARKET_MARKETS]\n",
    "\n",
    "if not markets_to_fetch:\n",
    "    print(\"No Polymarket markets configured.\")\n",
    "    print(\"Add market IDs to POLYMARKET_MARKETS or configure POLYMARKET_EVENT_MAPPING in config.py\")\n",
    "    polymarket_downloaded = []\n",
    "    polymarket_skipped = []\n",
    "    polymarket_errors = []\n",
    "else:\n",
    "    print(f\"Fetching/checking {len(markets_to_fetch)} Polymarket market(s)...\")\n",
    "    print(f\"Force reload: {FORCE_RELOAD}\")\n",
    "    print()\n",
    "    \n",
    "    polymarket_downloaded = []\n",
    "    polymarket_skipped = []\n",
    "    polymarket_errors = []\n",
    "    \n",
    "    for market_id, event_id in markets_to_fetch:\n",
    "        try:\n",
    "            if FORCE_RELOAD:\n",
    "                print(f\"Force reloading {market_id}...\")\n",
    "                fetch_market_history(market_id, force_reload=True)\n",
    "                polymarket_downloaded.append(market_id)\n",
    "            else:\n",
    "                if check_market_exists(market_id):\n",
    "                    print(f\"✓ {market_id}: Already exists, skipping\")\n",
    "                    polymarket_skipped.append(market_id)\n",
    "                else:\n",
    "                    print(f\"↓ {market_id}: Not found, fetching...\")\n",
    "                    fetch_market_history(market_id, force_reload=False)\n",
    "                    polymarket_downloaded.append(market_id)\n",
    "            \n",
    "            # Resample to daily\n",
    "            print(f\"  Resampling {market_id} to daily frequency...\")\n",
    "            resample_to_daily(market_id)\n",
    "        except Exception as e:\n",
    "            print(f\"✗ {market_id}: Error - {e}\")\n",
    "            polymarket_errors.append((market_id, str(e)))\n",
    "    \n",
    "    print()\n",
    "    print(f\"Polymarket Summary:\")\n",
    "    print(f\"  Markets downloaded: {len(polymarket_downloaded)}\")\n",
    "    if polymarket_downloaded:\n",
    "        print(f\"    {', '.join(polymarket_downloaded)}\")\n",
    "    print(f\"  Markets skipped: {len(polymarket_skipped)}\")\n",
    "    if polymarket_skipped:\n",
    "        print(f\"    {', '.join(polymarket_skipped)}\")\n",
    "    print(f\"  Errors: {len(polymarket_errors)}\")\n",
    "    if polymarket_errors:\n",
    "        for market_id, error in polymarket_errors:\n",
    "            print(f\"    - {market_id}: {error}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Overall summary of data fetching operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
