{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection for Large Yield Moves (Clean Evaluation)\n",
    "\n",
    "**Objective:**\n",
    "- Priority 1: Never miss abnormal events (FN = 0)\n",
    "- Priority 2: Minimize false alarms\n",
    "\n",
    "**Method:** Cost-Sensitive Random Forest with Time Series CV for threshold selection\n",
    "\n",
    "**Key Principle:** Test data is NEVER used for any tuning or model selection.\n",
    "\n",
    "---\n",
    "\n",
    "## Audit Checklist\n",
    "\n",
    "| Check | Status |\n",
    "|-------|--------|\n",
    "| Chronological train/val/test split | ✓ |\n",
    "| Features use only past data | ✓ |\n",
    "| Medians from train+val only | ✓ |\n",
    "| Scaler fitted on train+val only | ✓ |\n",
    "| Threshold from CV (not test) | ✓ |\n",
    "| Test touched only for final eval | ✓ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from src.models.prepare_data import prepare_event_data\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('Imports complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Data Loading and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "TARGET_YIELD = 'y_2y'\n",
    "LARGE_THRESHOLD = 0.10  # 10 basis points\n",
    "\n",
    "events_df = prepare_event_data(target_yield=TARGET_YIELD, prediction_horizon=0)\n",
    "events_df = events_df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Chronological split: 70% train+val, 30% test\n",
    "n_total = len(events_df)\n",
    "n_test = int(n_total * 0.3)\n",
    "n_trainval = n_total - n_test\n",
    "\n",
    "trainval_df = events_df.iloc[:n_trainval].copy()\n",
    "test_df = events_df.iloc[n_trainval:].copy()\n",
    "\n",
    "print('DATA SPLITS (chronological)')\n",
    "print('='*60)\n",
    "print(f'Train+Val: {len(trainval_df)} events ({trainval_df[\"date\"].min().date()} to {trainval_df[\"date\"].max().date()})')\n",
    "print(f'Test:      {len(test_df)} events ({test_df[\"date\"].min().date()} to {test_df[\"date\"].max().date()})')\n",
    "print(f'\\n*** Test data will NOT be touched until final evaluation ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define labels and clean data\n",
    "trainval_df['is_abnormal'] = trainval_df[f'{TARGET_YIELD}_change'].abs() > LARGE_THRESHOLD\n",
    "test_df['is_abnormal'] = test_df[f'{TARGET_YIELD}_change'].abs() > LARGE_THRESHOLD\n",
    "\n",
    "trainval_clean = trainval_df.dropna(subset=[f'{TARGET_YIELD}_change']).copy()\n",
    "test_clean = test_df.dropna(subset=[f'{TARGET_YIELD}_change']).copy()\n",
    "\n",
    "trainval_clean['cpi_abs'] = trainval_clean['cpi_shock_mom'].abs()\n",
    "test_clean['cpi_abs'] = test_clean['cpi_shock_mom'].abs()\n",
    "\n",
    "print('\\nLABEL DISTRIBUTION')\n",
    "print('-'*40)\n",
    "print(f'Train+Val abnormal: {trainval_clean[\"is_abnormal\"].sum()} ({trainval_clean[\"is_abnormal\"].mean():.1%})')\n",
    "print(f'Test abnormal:      {test_clean[\"is_abnormal\"].sum()} ({test_clean[\"is_abnormal\"].mean():.1%})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Time Series Cross-Validation for Threshold Selection\n",
    "\n",
    "Use CV on train+val to find a robust threshold. Test data is NOT used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['yield_volatility', 'cpi_shock_mom', 'fed_funds', 'slope_10y_2y', 'unemployment', 'cpi_abs']\n",
    "\n",
    "X_trainval = trainval_clean[FEATURES].copy()\n",
    "y_trainval = trainval_clean['is_abnormal'].values\n",
    "\n",
    "print('TIME SERIES CROSS-VALIDATION FOR THRESHOLD SELECTION')\n",
    "print('='*60)\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "cv_thresholds = []\n",
    "cv_fp_rates = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_trainval)):\n",
    "    X_tr = X_trainval.iloc[train_idx]\n",
    "    X_vl = X_trainval.iloc[val_idx]\n",
    "    y_tr = y_trainval[train_idx]\n",
    "    y_vl = y_trainval[val_idx]\n",
    "    \n",
    "    # Skip if no abnormals in validation\n",
    "    if y_vl.sum() == 0:\n",
    "        print(f'  Fold {fold+1}: skipped (no abnormals in validation)')\n",
    "        continue\n",
    "    \n",
    "    # Impute with train medians\n",
    "    medians = {col: X_tr[col].median() for col in FEATURES}\n",
    "    X_tr = X_tr.fillna(medians)\n",
    "    X_vl = X_vl.fillna(medians)\n",
    "    \n",
    "    # Scale\n",
    "    scaler = StandardScaler()\n",
    "    X_tr_scaled = scaler.fit_transform(X_tr)\n",
    "    X_vl_scaled = scaler.transform(X_vl)\n",
    "    \n",
    "    # Train\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100, max_depth=5,\n",
    "        class_weight={False: 1, True: 50},\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_tr_scaled, y_tr)\n",
    "    \n",
    "    # Find threshold for FN=0\n",
    "    val_probs = model.predict_proba(X_vl_scaled)[:, 1]\n",
    "    thresh = val_probs[y_vl].min() - 0.001\n",
    "    \n",
    "    # Compute FP rate\n",
    "    val_pred = val_probs >= thresh\n",
    "    fp_rate = (~y_vl & val_pred).sum() / (~y_vl).sum()\n",
    "    \n",
    "    cv_thresholds.append(thresh)\n",
    "    cv_fp_rates.append(fp_rate)\n",
    "    \n",
    "    print(f'  Fold {fold+1}: threshold={thresh:.4f}, FP rate={fp_rate:.1%}')\n",
    "\n",
    "# Use MAXIMUM threshold (most conservative for FN=0)\n",
    "robust_threshold = max(cv_thresholds)\n",
    "print(f'\\nRobust threshold (max across folds): {robust_threshold:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: Train Final Model on All Train+Val Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('FINAL MODEL TRAINING')\n",
    "print('='*60)\n",
    "\n",
    "# Compute medians from train+val\n",
    "trainval_medians = {col: trainval_clean[col].median() for col in FEATURES}\n",
    "\n",
    "# Prepare features\n",
    "X_trainval_clean = trainval_clean[FEATURES].fillna(trainval_medians)\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_trainval_scaled = scaler.fit_transform(X_trainval_clean)\n",
    "\n",
    "# Train final model\n",
    "final_model = RandomForestClassifier(\n",
    "    n_estimators=100, max_depth=5,\n",
    "    class_weight={False: 1, True: 50},\n",
    "    random_state=42\n",
    ")\n",
    "final_model.fit(X_trainval_scaled, y_trainval)\n",
    "\n",
    "print('Model trained on ALL train+val data')\n",
    "print(f'Threshold to use: {robust_threshold:.4f} (from CV)')\n",
    "print(f'\\n*** Test data still not touched ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 4: Final Test Evaluation (First Time Test is Touched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('FINAL TEST EVALUATION')\n",
    "print('='*70)\n",
    "print('\\n*** This is the FIRST and ONLY time test data is used ***\\n')\n",
    "\n",
    "# Prepare test features (using train+val medians)\n",
    "X_test = test_clean[FEATURES].fillna(trainval_medians)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_test = test_clean['is_abnormal'].values\n",
    "\n",
    "# Predict with pre-determined threshold\n",
    "test_probs = final_model.predict_proba(X_test_scaled)[:, 1]\n",
    "test_pred = test_probs >= robust_threshold\n",
    "\n",
    "# Compute metrics\n",
    "TP = (y_test & test_pred).sum()\n",
    "FP = (~y_test & test_pred).sum()\n",
    "FN = (y_test & ~test_pred).sum()\n",
    "TN = (~y_test & ~test_pred).sum()\n",
    "\n",
    "fn_rate = FN / y_test.sum() if y_test.sum() > 0 else 0\n",
    "fp_rate = FP / (~y_test).sum() if (~y_test).sum() > 0 else 0\n",
    "\n",
    "print(f'Threshold: {robust_threshold:.4f} (from CV, never saw test)')\n",
    "print(f'\\nRESULTS:')\n",
    "print(f'  FN Rate: {fn_rate:.1%} (missed abnormals)')\n",
    "print(f'  FP Rate: {fp_rate:.1%} (false alarms)')\n",
    "print(f'\\n  TP: {TP} (caught abnormals)')\n",
    "print(f'  FP: {FP} (false alarms)')\n",
    "print(f'  FN: {FN} (missed)')\n",
    "print(f'  TN: {TN} (correctly ignored)')\n",
    "\n",
    "if FN == 0:\n",
    "    print('\\n✓ Priority 1 achieved: All abnormal events caught!')\n",
    "else:\n",
    "    print(f'\\n⚠ {FN} abnormal events missed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Probability distribution\n",
    "ax1 = axes[0]\n",
    "ax1.hist(test_probs[~y_test], bins=30, alpha=0.6, label='Normal', color='blue')\n",
    "ax1.hist(test_probs[y_test], bins=15, alpha=0.6, label='Abnormal', color='red')\n",
    "ax1.axvline(x=robust_threshold, color='green', linestyle='--', linewidth=2, \n",
    "            label=f'Threshold={robust_threshold:.3f}')\n",
    "ax1.set_xlabel('Predicted Probability')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Test Set Probability Distribution')\n",
    "ax1.legend()\n",
    "\n",
    "# Confusion matrix\n",
    "ax2 = axes[1]\n",
    "cm = np.array([[TN, FP], [FN, TP]])\n",
    "im = ax2.imshow(cm, cmap='Blues')\n",
    "ax2.set_xticks([0, 1])\n",
    "ax2.set_yticks([0, 1])\n",
    "ax2.set_xticklabels(['Pred Normal', 'Pred Abnormal'])\n",
    "ax2.set_yticklabels(['Actual Normal', 'Actual Abnormal'])\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax2.text(j, i, cm[i, j], ha='center', va='center', fontsize=16, fontweight='bold')\n",
    "ax2.set_title('Confusion Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('SUMMARY')\n",
    "print('='*70)\n",
    "print(f'''\n",
    "METHOD: Cost-Sensitive Random Forest with Time Series CV\n",
    "\n",
    "  1. Split data chronologically: train+val (70%) | test (30%)\n",
    "  2. Use 5-fold Time Series CV on train+val to find threshold\n",
    "  3. Take MAX threshold across folds (most conservative)\n",
    "  4. Train final model on all train+val\n",
    "  5. Evaluate on test (first and only time touched)\n",
    "\n",
    "RESULTS:\n",
    "  FN Rate: {fn_rate:.1%}\n",
    "  FP Rate: {fp_rate:.1%}\n",
    "  \n",
    "  Catches {TP}/{TP+FN} abnormal events ({TP/(TP+FN)*100 if TP+FN > 0 else 0:.0f}%)\n",
    "  False alarms: {FP}/{FP+TN} normal events ({FP/(FP+TN)*100:.0f}%)\n",
    "\n",
    "AUDIT:\n",
    "  ✓ Test data never used for threshold selection\n",
    "  ✓ Test data never used for model training\n",
    "  ✓ Test data never used for feature statistics\n",
    "  ✓ All tuning done on train+val with CV\n",
    "  ✓ Zero information leakage from test\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
